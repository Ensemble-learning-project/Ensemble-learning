{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To implement a Decision Tree from scratch in Python using pandas and numpy, we'll start by defining a class DecisionTree and its associated methods. This implementation will support both classification and regression tasks, which will be determined by the task parameter when creating an instance of the Decision Tree."
      ],
      "metadata": {
        "id": "cdzsUTBPg2Jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class DecisionNode:\n",
        "    def __init__(self, feature=None, threshold=None, value=None, left=None, right=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.value = value\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, task='classification', min_samples_split=2, max_depth=None):\n",
        "        self.task = task\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.root = None\n",
        "\n",
        "    def _split(self, X, y, feature, threshold):\n",
        "        mask = X[:, feature] <= threshold\n",
        "        return X[mask], y[mask], X[~mask], y[~mask]\n",
        "\n",
        "    def _calculate_impurity(self, y):\n",
        "        if self.task == 'classification':\n",
        "            _, counts = np.unique(y, return_counts=True)\n",
        "            probabilities = counts / y.shape[0]\n",
        "            return 1 - np.sum(probabilities ** 2)\n",
        "        else:  # regression\n",
        "            return np.var(y)\n",
        "\n",
        "    def _calculate_information_gain(self, y, left_y, right_y):\n",
        "        parent_impurity = self._calculate_impurity(y)\n",
        "        left_impurity = self._calculate_impurity(left_y)\n",
        "        right_impurity = self._calculate_impurity(right_y)\n",
        "        return parent_impurity - len(left_y) / len(y) * left_impurity - len(right_y) / len(y) * right_impurity\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_gain = -np.inf\n",
        "        best_feature = None\n",
        "        best_threshold = None\n",
        "\n",
        "        for feature in range(X.shape[1]):\n",
        "            for threshold in np.unique(X[:, feature]):\n",
        "                left_y, right_y = self._split(X, y, feature, threshold)[1::2]\n",
        "                if len(left_y) == 0 or len(right_y) == 0:\n",
        "                    continue\n",
        "                gain = self._calculate_information_gain(y, left_y, right_y)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        if len(y) < self.min_samples_split or (self.max_depth is not None and depth == self.max_depth):\n",
        "            if self.task == 'classification':\n",
        "                return DecisionNode(value=np.argmax(np.bincount(y)))\n",
        "            else:  # regression\n",
        "                return DecisionNode(value=np.mean(y))\n",
        "\n",
        "        feature, threshold = self._find_best_split(X, y)\n",
        "        if feature is None:\n",
        "            if self.task == 'classification':\n",
        "                return DecisionNode(value=np.argmax(np.bincount(y)))\n",
        "            else:  # regression\n",
        "                return DecisionNode(value=np.mean(y))\n",
        "\n",
        "        left_X, left_y, right_X, right_y = self._split(X, y, feature, threshold)\n",
        "        left = self._build_tree(left_X, left_y, depth + 1)\n",
        "        right = self._build_tree(right_X, right_y, depth + 1)\n",
        "        return DecisionNode(feature=feature, threshold=threshold, left=left, right=right)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._build_tree(X, y)\n",
        "\n",
        "    def _predict_sample(self, x, node=None):\n",
        "        if node is None:\n",
        "            node = self.root\n",
        "\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._predict_sample(x, node.left)\n",
        "        else:\n",
        "            return self._predict_sample(x, node.right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_sample(x) for x in X])\n",
        "        if node is None:\n",
        "            node = self.root\n",
        "\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._predict_sample(x, node.left)\n",
        "        else:\n",
        "            return self._predict_sample(x, node.right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_sample(x) for x in X])\n",
        "\n"
      ],
      "metadata": {
        "id": "pkKHY9m8g2oh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage example\n",
        "if __name__ == '__main__':\n",
        "    from sklearn.datasets import load_iris\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "    # Classification\n",
        "    data = load_iris()\n",
        "    X, y = data.data, data.target\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    tree = DecisionTree(task='classification', min_samples_split=5, max_depth=3)\n",
        "    tree.fit(X_train, y_train)\n",
        "    y_pred = tree.predict(X_test)\n",
        "    print(\"Classification accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# regression\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the diabetes dataset\n",
        "data = load_diabetes()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and fit the DecisionTree\n",
        "tree = DecisionTree(task='regression', min_samples_split=10, max_depth=5)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate the performance\n",
        "y_pred = tree.predict(X_test)\n",
        "print(\"Regression mean squared error:\", mean_squared_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El-vZ8URi77i",
        "outputId": "8ea5c52e-b53d-4096-9df6-5d7e9f977276"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification accuracy: 1.0\n",
            "Regression mean squared error: 3454.2915559860116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deuxiÃ¨me exemple pour tester la classification"
      ],
      "metadata": {
        "id": "KOpB3Tj6kkFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the wine dataset\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and fit the DecisionTree\n",
        "tree = DecisionTree(task='classification', min_samples_split=5, max_depth=3)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate the performance\n",
        "y_pred = tree.predict(X_test)\n",
        "print(\"Classification accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb2b3RXKjPM4",
        "outputId": "3d34f5bb-c01e-4dd5-e8d1-313174711c2c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification accuracy: 0.9444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2M8Eihh7iNfR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}